import pandas as pd
from sklearn.metrics import confusion_matrix

# Load your datasets
df_main = pd.read_csv('main_dataset.csv')  # your original dataset
df_age = pd.read_csv('age_dataset.csv')  # dataset containing age_grp_cd

# Merge the age data with the main dataset
df = pd.merge(df_main, df_age[['PRTCP_ID', 'Age_grp_cd']], on='PRTCP_ID')

# Make predictions on the dataset (assuming your model is already trained as `model`)
X = df.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])  # Exclude 'age_grp_cd' and 'PRTCP_ID' from features
y_true = df['STP_DFR_TRGT']  # Actual labels
y_pred = model.predict(X)

# Separate predictions by age group
age_group_0_38 = df[df['Age_grp_cd'] == 1]
age_group_above_38 = df[df['Age_grp_cd'] == 0]

# Disparate impact calculation
def disparate_impact(y_pred, y_true):
    cm = confusion_matrix(y_true, y_pred)
    tp, fn, fp, tn = cm.ravel()
    return (tp + fp) / (tp + fn + fp + tn)  # Ratio of positive predictions

# Calculate Disparate Impact for both age groups
di_0_38 = disparate_impact(age_group_0_38['STP_DFR_TRGT'], model.predict(age_group_0_38.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])))
di_above_38 = disparate_impact(age_group_above_38['STP_DFR_TRGT'], model.predict(age_group_above_38.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])))

print(f'Disparate Impact (0-38): {di_0_38}')
print(f'Disparate Impact (Above 38): {di_above_38}')



import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split

# Define the adversarial network to predict Age_grp_cd
def build_adversarial_debiaser(input_dim):
    model = tf.keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_dim,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')  # Predicts Age_grp_cd (0 or 1)
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Training loop for debiasing (XGB + Adversarial model)
def adversarial_training(xgb_model, adversarial_model, X_train, y_train, y_age, epochs=10):
    for epoch in range(epochs):
        # Train the main model (XGBoost)
        xgb_model.fit(X_train, y_train)
        
        # Get predictions (intermediate outputs) from XGBoost for adversarial model training
        y_pred_proba = xgb_model.predict_proba(X_train)[:, 1]  # Predict probabilities for STP_DFR_TRGT
        
        # Train the adversarial model to predict Age_grp_cd from the predicted probabilities
        adversarial_loss = adversarial_model.fit(y_pred_proba.reshape(-1, 1), y_age, epochs=1, batch_size=64, verbose=1)
        
        # Get adversarial loss (penalty) and adjust model accordingly
        loss = adversarial_loss.history['loss'][-1]
        print(f"Epoch {epoch+1}/{epochs}, Adversarial Loss: {loss}")
    
    return xgb_model

# Prepare data for training
X = df.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])
y_train = df['STP_DFR_TRGT']
y_age = df['Age_grp_cd']

# Split the data into training and test sets
X_train, X_test, y_train, y_test, y_age_train, y_age_test = train_test_split(X, y_train, y_age, test_size=0.2, random_state=42)

# Initialize models
xgb_model = xgb.XGBClassifier()
adversarial_model = build_adversarial_debiaser(1)  # Debiasing model takes in predicted probabilities (1-dimensional)

# Train with adversarial debiasing
xgb_debiased = adversarial_training(xgb_model, adversarial_model, X_train, y_train, y_age_train)

# Post-training evaluation
y_pred_debiased = xgb_debiased.predict(X_test)

# Recalculate Disparate Impact after debiasing
di_0_38_debiased = disparate_impact(age_group_0_38['STP_DFR_TRGT'], xgb_debiased.predict(age_group_0_38.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])))
di_above_38_debiased = disparate_impact(age_group_above_38['STP_DFR_TRGT'], xgb_debiased.predict(age_group_above_38.drop(columns=['STP_DFR_TRGT', 'PRTCP_ID', 'Age_grp_cd'])))

print(f'Post-Mitigation Disparate Impact (0-38): {di_0_38_debiased}')
print(f'Post-Mitigation Disparate Impact (Above 38): {di_above_38_debiased}')